# 웹 로봇

웹 로봇의 몇 가지 예
* 주식시장 서버에 매 분 HTTP GET 요청을 보내고, 여기서 얻은 데이터를 활용해 주가 추이 그래프를 생성하는 주식 그래프 로봇
* 월드 와이드 웹의 규모와 진화에 대한 통계 정보를 수집하는 웹 통계 조사 로봇. 웹을 떠돌면서 페이지의 개수를 세고, 각 페이지의 크기, 언어, 미디어 타입을 기록한다.
* 검색 데이터베이스를 만들기 위해 발견한 모든 문서를 수집하는 검색엔진 로봇
* 상품에 대한 가격 데이터베이스를 만들기 위해 온라인 쇼핑몰의 카탈로그에서 웹피이지를 수집하는 가격 비교 로봇

## 크롤러와 크롤링

웹 크롤러는 웹 페이지를 한 개 가져오고, 그 다음 그 페이지가 가리키는 모든 웹페이지를 가져오며 재ㅔ귀적으로 반복하는 방식으로 웹을 순회하는 로봇이다. 웹 링크를 재귀적으로 따라가는 로봇을 **크롤러** 또는 **스파이더**라고 부른다.

### 어디에서 시작하는가: '루트 집합'

크롤러가 방문을 시작하는 URL들의 초기 집합을 **루트 집합**(root set)이라고 부른다. 루트 집합을 고를 때, 모든 링크를 크롤링하면 결과적으로 관심 있는 웹페이지들의 대부분을 가져오게 될 수 있도록 충분히 다른 장소에서 URL들을 선택해야 한다.

일반적으로 좋은 루트 집합은 크고 인기 있는 웹 사이트, 새로 생성된 페이지들의 목록, 그리고 자주 링크되지 않는 잘 알려져 있지 않은 페이지들의 목록으로 구성되어 있다.

### 링크 추출과 상대 링크 정상화

크롤러는 웹을 돌아다니면서 꾸준히 HTML 문서를 검색한다. 크롤러는 검색한 각 페이지 안에 들어있는 URL 링크들을 파싱해서 크롤링할 페이지들의 목록에 추가해야 한다. 링크들을 추출하고 상대 링크를 절대 링크로 변환할 필요가 있다.

### 순환 피하기

로봇이 웹을 크롤링할 때, 루프나 순환에 빠지지 않도록 매우 조심해야 한다. 로봇들은 순환을 피하기 위해 반드시 그들이 어디를 방문했는지 알아야 한다. 순환은 로봇을 함정에 빠뜨려서 멈추게 하거나 진행을 느려지게 한다.

### 루프와 중복

* 순환은 크롤러를 루프에 빠뜨려서 꼼짝 못하게 만들 수 있다.
* 크롤러가 같은 페이지를 반복해서 가져오면 웹 서버의 부담이 된다. 실제 사용자도 사이트에 접근할 수 없도록 막아버리게 될 수도 있으며, 법적인 문제제기의 근거가 될 수도 있다.
* 루프 자체가 문제가 되지 않더라도, 크롤러는 많은 수의 중복된 페이지들을 가져오게 된다.

### 빵 부스러기의 흔적

방문한 곳을 지속적으로 추적하는 것은 쉽지 않다. 어떤 URL을 방문했는지 빠르게 판단하기 위해서는 복잡한 자료 구조를 사용할 필요가 있다. 이 자료 구조는 속도와 메모리 사용 면에서 효과적이어야 한다.

수억 개의 URL은 빠른 검색 구조를 요구하기 때문에 빠른 속도는 중요하다. 로봇은 어떤 URL이 방문했던 곳인지 빠르게 결정하기 위해 적어도 검색 트리나 해시 테이블을 필요로 할 것이다.

대규모 웹 크롤러가 그들이 방문한 곳을 관리하기 위해 사용하는 유용한 기법을 몇 가지 들어보면 다음과 같다.

* 트리와 해시 테이블
    * 방문한 URL을 추적하기 위해 검색 트리나 해시 테이블을 사용했을 수 있다. 
* 느슨한 존재 비트맵
    * 공간 사용을 최소화하기 위해, 몇몇 대규모 크롤러들은 존재 비트 배열(presence bit array)과 같은 느슨한 자료 구조를 사용한다. 각 URL은 해시 함수에 의해 고정된 크기의 숫자로 변환되고 배열 안에 대응하는 '존재 비트(presence bit)'를 갖는다. URL이 크롤링 되었을 때 해당하는 존재 비트가 만들어진다. 존재 비트가 이미 존재한다면 이미 크롤링 되었다고 간주한다.
* 체크포인트
    * 로봇 프로그램이 갑작스럽게 중단될 경우를 대비해, 방문한 URL의 목록이 디스크에 저장되었는지 확인한다.
* 파티셔닝
    * 웹의 성장으로, 한 대의 컴퓨터에서 하나의 로봇이 크롤링을 완수하는 것은 불가능해졌다. 몇몇 대규모 웹 로봇은, 각각이 분리된 한 대의 컴퓨터인 로봇들이 동시에 일하고 있는 '농장(farm)'을 이용한다. 각 로봇엔 URL들의 특정 '한 부분'이 할당되어 그에 대한 책임을 진다. 로봇들은 서로 도와 웹을 크롤링한다. 개별 로봇들은 URL들을 이리저리 넘겨주거나, 오동족하는 동료를 도와주거나, 활동을 조정하기 위해 커뮤니케이션을 할 필요가 있다.

### 별칭(alias)과 로봇 순환

### URL 정규화하기

### 파일 시스템 링크 순환

### 동적 가상 웹 공간

### 루프와 중복 피하기

## 로봇의 HTTP


